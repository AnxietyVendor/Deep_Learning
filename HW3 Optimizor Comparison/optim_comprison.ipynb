{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MThPwqzzQiu"
      },
      "source": [
        "# 载入必要的函数库\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import Model\n",
        "from keras.layers import Dense,Flatten,Input\n",
        "from keras.optimizers import SGD,RMSprop,Adam\n",
        "from keras.models import Sequential # 导入models模块中的Sequential容器\n",
        "\n",
        "from keras.utils import to_categorical "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIeFm2nCzdRw",
        "outputId": "e437d740-b5c7-45a6-d4f6-f43327c75fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## 载入mnist数据集\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() \n",
        "\n",
        "## 转换为one - hot型向量\n",
        "Y_train=to_categorical(y_train)\n",
        "Y_test=to_categorical(y_test)\n",
        "\n",
        "print(Y_train.shape)\n",
        "print(Y_train[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLrKfBj12Rgn",
        "outputId": "7ccdb3c6-8166-42cd-9225-511fc59a5a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "'''\n",
        " 实验：构建 Multi-layer Nueral Network 模型 \n",
        "'''\n",
        "\n",
        "##  第一步  创建模型结构 ##\n",
        "\n",
        "IMSIZE = 28                                               \n",
        "\"\"\"\n",
        "input_layer = Input([IMSIZE,IMSIZE])       # MNIST图像为28*28的单层图片\n",
        "x = input_layer                              \n",
        "x = Flatten()(input_layer)                   # 将28*28*1的Tensor拉直为784维向量\n",
        "x = Dense(1000,activation = 'relu')(x)       # 全连接到1000个节点，并采用relu激活函数\n",
        "x = Dense(10,activation = 'softmax')(x)      # 全连接到10个节点，并采用softmax激活函数转化为(0,1)取值\n",
        "output_layer=x\n",
        "model=Model(input_layer,output_layer)    # Model函数将input_layer 和 output_layer中间的部分连接起来\n",
        "\"\"\"\n",
        "model = Sequential([Input([IMSIZE,IMSIZE]),Flatten(),Dense(1000,activation='relu'),Dense(10,activation='softmax')]) # 使用sequential容器配置训练模型\n",
        "model.summary()\n",
        "\n",
        "##  第二步  模型编译 ##\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=SGD(lr=0.001),metrics=['accuracy'])\n",
        "\n",
        "##  第三步  模型拟合 ##\n",
        "\n",
        "history1 = model.fit(X_train,Y_train, validation_data=(X_test,Y_test), batch_size=1000, epochs=50)\n",
        "\n",
        "# 第四部  提取loss指标\n",
        "# model.fit会返回一个history对象，里面记录了训练集和测试集的loss以及acc\n",
        "# 我们将这些指标取出，绘制折线图\n",
        "\n",
        "train_loss1 = history1.history[\"loss\"]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 4s 73ms/step - loss: 22.0076 - accuracy: 0.8123 - val_loss: 2.7461 - val_accuracy: 0.8975\n",
            "Epoch 2/50\n",
            "60/60 [==============================] - 4s 70ms/step - loss: 2.0617 - accuracy: 0.9091 - val_loss: 1.9415 - val_accuracy: 0.9164\n",
            "Epoch 3/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 1.4302 - accuracy: 0.9259 - val_loss: 1.6365 - val_accuracy: 0.9241\n",
            "Epoch 4/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 1.0852 - accuracy: 0.9363 - val_loss: 1.4366 - val_accuracy: 0.9279\n",
            "Epoch 5/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.8672 - accuracy: 0.9441 - val_loss: 1.3140 - val_accuracy: 0.9306\n",
            "Epoch 6/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.7099 - accuracy: 0.9511 - val_loss: 1.2512 - val_accuracy: 0.9337\n",
            "Epoch 7/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.5949 - accuracy: 0.9561 - val_loss: 1.1672 - val_accuracy: 0.9355\n",
            "Epoch 8/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.4977 - accuracy: 0.9615 - val_loss: 1.1267 - val_accuracy: 0.9362\n",
            "Epoch 9/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.4250 - accuracy: 0.9646 - val_loss: 1.0717 - val_accuracy: 0.9380\n",
            "Epoch 10/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.3633 - accuracy: 0.9690 - val_loss: 1.0345 - val_accuracy: 0.9377\n",
            "Epoch 11/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.3176 - accuracy: 0.9717 - val_loss: 1.0265 - val_accuracy: 0.9377\n",
            "Epoch 12/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.2723 - accuracy: 0.9740 - val_loss: 1.0071 - val_accuracy: 0.9392\n",
            "Epoch 13/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.2389 - accuracy: 0.9770 - val_loss: 0.9849 - val_accuracy: 0.9395\n",
            "Epoch 14/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.2078 - accuracy: 0.9785 - val_loss: 0.9754 - val_accuracy: 0.9409\n",
            "Epoch 15/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.1837 - accuracy: 0.9807 - val_loss: 0.9590 - val_accuracy: 0.9407\n",
            "Epoch 16/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.1605 - accuracy: 0.9827 - val_loss: 0.9478 - val_accuracy: 0.9403\n",
            "Epoch 17/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.1412 - accuracy: 0.9836 - val_loss: 0.9323 - val_accuracy: 0.9423\n",
            "Epoch 18/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.1237 - accuracy: 0.9853 - val_loss: 0.9309 - val_accuracy: 0.9419\n",
            "Epoch 19/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.1080 - accuracy: 0.9870 - val_loss: 0.9320 - val_accuracy: 0.9422\n",
            "Epoch 20/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0936 - accuracy: 0.9886 - val_loss: 0.9320 - val_accuracy: 0.9410\n",
            "Epoch 21/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0825 - accuracy: 0.9899 - val_loss: 0.9240 - val_accuracy: 0.9422\n",
            "Epoch 22/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0716 - accuracy: 0.9915 - val_loss: 0.9203 - val_accuracy: 0.9415\n",
            "Epoch 23/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0632 - accuracy: 0.9923 - val_loss: 0.9167 - val_accuracy: 0.9417\n",
            "Epoch 24/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0554 - accuracy: 0.9932 - val_loss: 0.9124 - val_accuracy: 0.9416\n",
            "Epoch 25/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0478 - accuracy: 0.9941 - val_loss: 0.9085 - val_accuracy: 0.9423\n",
            "Epoch 26/50\n",
            "60/60 [==============================] - 4s 74ms/step - loss: 0.0417 - accuracy: 0.9949 - val_loss: 0.9059 - val_accuracy: 0.9422\n",
            "Epoch 27/50\n",
            "60/60 [==============================] - 4s 74ms/step - loss: 0.0366 - accuracy: 0.9952 - val_loss: 0.9049 - val_accuracy: 0.9419\n",
            "Epoch 28/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0316 - accuracy: 0.9963 - val_loss: 0.9038 - val_accuracy: 0.9419\n",
            "Epoch 29/50\n",
            "60/60 [==============================] - 4s 73ms/step - loss: 0.0276 - accuracy: 0.9964 - val_loss: 0.9000 - val_accuracy: 0.9419\n",
            "Epoch 30/50\n",
            "60/60 [==============================] - 4s 74ms/step - loss: 0.0237 - accuracy: 0.9973 - val_loss: 0.8981 - val_accuracy: 0.9423\n",
            "Epoch 31/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0206 - accuracy: 0.9975 - val_loss: 0.8943 - val_accuracy: 0.9428\n",
            "Epoch 32/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0178 - accuracy: 0.9980 - val_loss: 0.8956 - val_accuracy: 0.9427\n",
            "Epoch 33/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0155 - accuracy: 0.9984 - val_loss: 0.8938 - val_accuracy: 0.9426\n",
            "Epoch 34/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0134 - accuracy: 0.9985 - val_loss: 0.8902 - val_accuracy: 0.9437\n",
            "Epoch 35/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.8906 - val_accuracy: 0.9435\n",
            "Epoch 36/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0102 - accuracy: 0.9990 - val_loss: 0.8892 - val_accuracy: 0.9438\n",
            "Epoch 37/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.8873 - val_accuracy: 0.9439\n",
            "Epoch 38/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.8868 - val_accuracy: 0.9439\n",
            "Epoch 39/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 0.8861 - val_accuracy: 0.9440\n",
            "Epoch 40/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.8854 - val_accuracy: 0.9442\n",
            "Epoch 41/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0055 - accuracy: 0.9996 - val_loss: 0.8847 - val_accuracy: 0.9441\n",
            "Epoch 42/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0049 - accuracy: 0.9997 - val_loss: 0.8835 - val_accuracy: 0.9442\n",
            "Epoch 43/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.8824 - val_accuracy: 0.9437\n",
            "Epoch 44/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.8829 - val_accuracy: 0.9438\n",
            "Epoch 45/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.8820 - val_accuracy: 0.9441\n",
            "Epoch 46/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.8807 - val_accuracy: 0.9444\n",
            "Epoch 47/50\n",
            "60/60 [==============================] - 4s 72ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.8800 - val_accuracy: 0.9444\n",
            "Epoch 48/50\n",
            "60/60 [==============================] - 4s 71ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.8798 - val_accuracy: 0.9446\n",
            "Epoch 49/50\n",
            "60/60 [==============================] - 4s 73ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.8786 - val_accuracy: 0.9445\n",
            "Epoch 50/50\n",
            "60/60 [==============================] - 4s 75ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.8786 - val_accuracy: 0.9443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZH_pj0d3Tni",
        "outputId": "88af7022-9da7-405e-ace5-7a9a3bbd606c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "x = np.arange(50) # 生成0:49的连续整数代表epoch\n",
        "y = train_loss1 # 将history对象的loss属性命名为y\n",
        "plt.plot(x,y,color='red',label='SGD') # 绘制x-y散点图并用红色平滑曲线连接，图例为SGD\n",
        "plt.legend(title='loss curves of different optimizers') # 设置图例标题为不同优化器下的损失曲线\n",
        "plt.xlabel('epoch') # 设置横轴表示epoch\n",
        "plt.ylabel('accuracy') # 设置纵轴表示accuracy\n",
        "plt.show() # 绘制图像"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L-oT54x64JW",
        "outputId": "ecdb4642-0baf-45ef-fc84-0db910a747d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        }
      },
      "source": [
        "from keras.models import Sequential # 导入models模块中的Sequential容器\n",
        "\n",
        "optim_list = ['SGD','RMSprop','Adagrad','Adadelta','Adam','Adamax','Nadam'] # 新建一个列表来存储所有优化器的名称\n",
        "color_list = ['red','orange','yellow','green','blue','purple','grey'] # 新建一个列表来储存不同优化器对应损失曲线的颜色\n",
        "\n",
        "for i in range(7): # 生成0:6的连续整数代表7种优化器的下标\n",
        "  print('Optimizer:') # 输出当前模型使用的优化器名称\n",
        "  print(optim_list[i])\n",
        "  IMSIZE = 28 # 设置输入图像的长宽为28像素\n",
        "  \"\"\"                                               \n",
        "  input_layer = Input([IMSIZE,IMSIZE])       # MNIST图像为28*28的单层图片\n",
        "  x = input_layer                              \n",
        "  x = Flatten()(input_layer)                   # 将28*28*1的Tensor拉直为784维向量\n",
        "  x = Dense(1000,activation = 'relu')(x)       # 全连接到1000个节点，并采用relu激活函数\n",
        "  x = Dense(10,activation = 'softmax')(x)      # 全连接到10个节点，并采用softmax激活函数转化为(0,1)取值\n",
        "  output_layer=x\n",
        "  model = Model(input_layer,output_layer)    # Model函数将input_layer 和 output_layer中间的部分连接起来\n",
        "  \"\"\"\n",
        "  model = Sequential([Input([IMSIZE,IMSIZE]),Flatten(),Dense(1000,activation='relu'),Dense(10,activation='softmax')]) # 使用sequential容器配置训练模型\n",
        "  model.summary() #　输出模型信息\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',optimizer=optim_list[i],metrics=['accuracy']) # 模型编译，损失函数为交叉熵，优化器为优化器列表中的下标为i的优化器，性能度量指标为accuracy准确率\n",
        "\n",
        "  trained_model = model.fit(X_train,Y_train, validation_data=(X_test,Y_test), batch_size=1000, epochs=50) # 训练模型，每批1000张图，一共50批\n",
        "  x = np.arange(50) # 生成0:49的连续整数代表epoch　\n",
        "  y = trained_model.history[\"loss\"] # 将history对象的loss属性命名为y\n",
        "  plt.plot(x,y,color=color_list[i],label=optim_list[i])# 绘制当前优化器下的损失曲线，并设置对应的图例\n",
        "  plt.legend(title='loss curves of different optimizers') # 设定图片标题\n",
        "plt.xlabel('epoch') #　设置横坐标为epoch\n",
        "plt.ylabel('accuracy') # 设置纵坐标为accuracy\n",
        "plt.show() # 绘制图像\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimizer:\n",
            "SGD\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1000)              785000    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                10010     \n",
            "=================================================================\n",
            "Total params: 795,010\n",
            "Trainable params: 795,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "60/60 [==============================] - 4s 73ms/step - loss: 682.2188 - accuracy: 0.6188 - val_loss: 0.6291 - val_accuracy: 0.8392\n",
            "Epoch 2/50\n",
            "10/60 [====>.........................] - ETA: 2s - loss: 0.5710 - accuracy: 0.8479"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-43e433ad0a76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptim_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 模型编译，损失函数为交叉熵，优化器为优化器列表中的下标为i的优化器，性能度量指标为accuracy准确率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m   \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 训练模型，每批1000张图，一共50批\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 生成0:49的连续整数代表epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 将history对象的loss属性命名为y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}